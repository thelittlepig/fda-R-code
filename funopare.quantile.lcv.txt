funopare.quantile.lcv <- function(Response, CURVES, PRED, ..., alpha = c(0.05, 0.5, 0.95), Knearest = NULL, kind.of.kernel = "quadratic", semimetric = "deriv")
{
################################################################
# Performs functional prediction of a scalar response from a 
# sample of curves by computing the functional conditional mode. 
# A local bandwidth (i.e. local number of neighbours) is selected 
# by a ``trivial'' cross-validation procedure.
#    "Response" vector containing the observations of the scalar 
#               response
#    "CURVES" matrix containing the curves dataset (row by row) 
#             used for the estimating stage
#    "PRED" matrix containing new curves stored row by row
#           used for computing predictions
#    "..." arguments needed for the call of the function computing 
#          the semi-metric between curves
#    "alpha"  vector giving the quantiles to be computed. By default, 
#             the 5-percentile, median and 95-percentile are computed.
#    "Knearest"  vector giving the the sequence of successive authorized 
#                integers for the smoothing parameters. By default 
#                (i.e. Knearest=NULL), the vector Knearest contains a 
#                sequence of 10 integers taking into account card(I1).
#    "kind.of.kernel" the kernel function used for computing of 
#                     the kernel estimator; you can choose 
#                     "indicator", "triangle" or "quadratic (default)
#    "semimetric" character string allowing to choose the function 
#                 computing the semimetric;  you can select 
#                 "deriv" (default), "fourier", "hshift", "mplsr", 
#                 and "pca"
# Returns a list containing:
#    "Estimated.values" a  card(I2)-by-length(alpha) matrix whose 
#                       columns gives the corresponding estimated 
#                       conditional quantiles, for all curves in the 
#                       second learning subsample I2, 
#    "Predicted.values" if PRED different from CURVES, this matrix 
#                       contains predicted conditional quantiles 
#                       for each curve of PRED
#    "Response.values"  vector of length the size of the second 
#                       learning subsample giving the corresponding  
#                       observed responses.
#    "Mse" mean squared error between estimated values and 
#          observed values
################################################################
        Response <- as.vector(Response)
	Logicalpha <- alpha==0.5
	nomedian <- !as.logical(sum(Logicalpha))
	if(nomedian) stop("Please, add in the argument alpha the median (i.e 0.5)")
	lalpha <- length(alpha)
	testalpha <- lalpha > 1
	if(testalpha) posmedian <- (1:lalpha)[Logicalpha] 
	if(is.vector(PRED)) PRED <- as.matrix(t(PRED))
	onerow <- nrow(PRED) == 1
	testfordim <- sum(dim(CURVES)==dim(PRED))==2
	twodatasets <- T
	if(testfordim) twodatasets <- sum(CURVES==PRED)!=prod(dim(CURVES))
	sm <- get(paste("semimetric.", semimetric, sep = ""))
	kernel <- get(kind.of.kernel)
	int.kernel <- get(paste("integrated.", kind.of.kernel, sep = ""))
	llearn <- nrow(CURVES)
	Learn1 <- seq(2, llearn, by=2)
	llearn1 <- length(Learn1)
	LEARN1 <- CURVES[Learn1,  ]
	LEARN2 <- CURVES[ - Learn1,  ]
	if(semimetric == "mplsr"){
		SMLEARN1 <- sm(Response, LEARN1, LEARN1, ...)
		SMLEARN12 <- sm(Response, LEARN1, LEARN2, ...)
	} else {
		SMLEARN1 <- sm(LEARN1, LEARN1, ...)
		SMLEARN12 <- sm(LEARN1, LEARN2, ...)
	}
	SML12.SOR <- apply(SMLEARN12, 2, sort)
	Resp1 <- Response[Learn1]
	Resp2 <- Response[ - Learn1]
	Resp.range <- range(Response)
	Response.grid <- seq(from = Resp.range[1] * 0.9, to = Resp.range[2] * 
		1.1, length = 100)	
	# RESPMETRIC[i,j]=yi-yj with i in Response.grid and j in LEARN1 
	RESPMETRIC <- outer(Response.grid, Resp1, "-")
	RESPMET.SOR <- t(apply(abs(RESPMETRIC), 1, sort))
	llearn2 <- nrow(LEARN2)
	lgrid <- length(Response.grid)
	if(is.null(Knearest)) {
		Knearest.min <- max(ceiling(llearn1 * 0.05), 10)
		Knearest.max <- ceiling(llearn1 * 0.25)
                if(Knearest.max <= Knearest.min){
                        Knearest.min <- ceiling(llearn1 * 0.05)
                }
		step <- ceiling((Knearest.max - Knearest.min)/10)
		Knearest <- seq(Knearest.min, Knearest.max, by = step)
	}
	lknearest <- length(Knearest)
	BANDL12.CUR <- 0.5 * (SML12.SOR[Knearest,  ] + SML12.SOR[Knearest + 1, ])
	BAND.RESP <- 0.5 * (RESPMET.SOR[, Knearest] + RESPMET.SOR[, Knearest + 
		1])
	CV <- matrix(0, nrow = lknearest^2, ncol = llearn2)
	if(testalpha){
		QUANT <- array(0, dim = c(lknearest^2, llearn2, lalpha))
		
	} else {
		QUANT <- matrix(0, nrow = lknearest^2, ncol = llearn2)
	}
	count <- 0
	for(kk in 1:lknearest) {
		ARG <- t(t(SMLEARN12)/BANDL12.CUR[kk,])
		KERNEL.CURVES <- kernel(ARG)
		KERNEL.CURVES[KERNEL.CURVES < 0] <- 0
		KERNEL.CURVES[KERNEL.CURVES > 1] <- 0
		Denom <- apply(KERNEL.CURVES, 2, sum)
		for(hh in 1:lknearest) {
			count <- count + 1
			IKERNEL.RESP <- apply(RESPMETRIC/BAND.RESP[, hh], 1,
				int.kernel)
			CDF.EST <- (t(KERNEL.CURVES)/Denom) %*% IKERNEL.RESP
			if(testalpha){
				for(ii in 1:lalpha){
				      Ind.quant <- apply(CDF.EST < alpha[ii], 1, sum)
				      Ind.quant[Ind.quant==0] <- 1
				      QUANT[count,,ii] <- Response.grid[Ind.quant]
				 }
				CV[count,] <- (Resp2 - QUANT[count,,posmedian])^2
			} else {
				Ind.quant <- apply(CDF.EST < alpha, 1, sum)
				Ind.quant[Ind.quant==0] <- 1
				QUANT[count, ] <- Response.grid[Ind.quant]
				CV[count, ] <- (Resp2 - QUANT[count,  ])^2
			}
		}
	}
	Ind.knearest.opt <- apply(CV, 2, order)[1,  ]
	IND.OPT <- cbind(Ind.knearest.opt, 1:llearn2)
	if(testalpha){
		Indkopt <- rep(Ind.knearest.opt, lalpha)
		Units <- rep(1:llearn2, lalpha) 
		Typeofest <- sort(rep(1:lalpha,llearn2))
		RESPONSE.ESTIMATED <- matrix(QUANT[cbind(Indkopt,Units,Typeofest)], nrow=llearn2, byrow=F)
		dimnames(RESPONSE.ESTIMATED) <- list(NULL, as.character(alpha))
	} else {
		RESPONSE.ESTIMATED <- QUANT[IND.OPT]
	}
	Mse.estimated <- sum(CV[IND.OPT])/llearn2
	if(twodatasets) {
		if(semimetric == "mplsr")
			SMLEARN2NEW <- sm(Response, LEARN2, PRED, ...)
		else SMLEARN2NEW <- sm(LEARN2, PRED, ...)
		Order.new <- apply(SMLEARN2NEW, 2, order)[1,  ]
		if(testalpha){
			if(onerow){
				RESPONSE.PREDICTED <- as.matrix(t(RESPONSE.ESTIMATED[Order.new,]))
			} else {
				RESPONSE.PREDICTED <- as.matrix(RESPONSE.ESTIMATED[Order.new,])
				dimnames(RESPONSE.PREDICTED) <- list(NULL, as.character(alpha))}
		} else {
			RESPONSE.PREDICTED <- RESPONSE.ESTIMATED[Order.new]
		}
		return(list(Estimated.values = RESPONSE.ESTIMATED, 
			Predicted.values = RESPONSE.PREDICTED, Response.values
			 = Resp2, Mse = Mse.estimated))
	}
	else {
		return(list(Estimated.values = RESPONSE.ESTIMATED, 
			Response.values = Resp2, Mse = Mse.estimated))
	}
}